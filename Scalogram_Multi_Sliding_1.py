from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50
#from tensorflow.keras.preprocessing import image
import keras.utils as image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import numpy as np
import pandas as pd
#!pip install Pillow
import sklearn
import os, glob
import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt


import pywt
#!pip install keras
import keras
#!pip install seaborn
import seaborn as sns
from sklearn.manifold import TSNE
from PIL import Image

import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpus[0], True)

# %load anomaly_scalograms.py
"""anomaly_scalograms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2OKY61ClOP-vmIErPdLy-aeZcpnYiV7
"""
path = os.getcwd()
print(path)
window_time = 50
slide_time = 5
sub_samp = 250 #freq = 250/sub_samp
l= int(window_time*250/sub_samp) #
slide = int(slide_time*250/sub_samp)

scales = np.arange(1,33)
wavelet = 'morl'
vmin =1
vmax = 0
cols = ['SPPA', 'TQA','MFIA']
df = pd.read_csv("/home/user/Desktop/Data/Confidential_Well_Data/AnomalyTestData/surface_data_1hz/edr.csv", usecols = cols,delimiter = ";",encoding = 'unicode_escape', skiprows = [1])#diff_df = df.diff().drop(index = 0).reset_index().drop(columns = 'index')
n = int((len(df)-l)/(slide)) +1
#diff_df = df.diff().drop(index = 0).reset_index().drop(columns = 'index')  # differenced power signal data. Anomalies in these scalograms are more pronounced than the ones with the original signal

#THIS is to generate scalograms

'''
    for i in tqdm(range(1,n+1)):
        dff = df.loc[slide*(i-1): l+(slide*(i-1)),col]
        data_in_use = np.array(dff) 
        data_in_use[np.abs(data_in_use) < 0.001] = 0

        #if data_in_use.max() == 0.0 or data_in_use.min() == 0.0:
         # continue
        coef, freqs=pywt.cwt(data_in_use,scales,wavelet = wavelet)
        mod_coeff = np.abs(coef)
        file_path = '/home/user/Desktop/jupyter1/DDP/Scalograms_'+col+'_Sliding_50_5/' + str(i) + '_sc.png'
        if np.amin(mod_coeff) < vmin:
          vmin = np.amin(mod_coeff)
        else:
          pass
        if np.amax(mod_coeff) > vmax:
          vmax = np.amax(mod_coeff)
        else:
          pass

        plt.figure(figsize = (20,20))
        plt.imshow(np.abs(coef), origin = 'lower', cmap = 'coolwarm', aspect = 'auto',
              vmin = vmin, vmax = vmax)
        plt.title('Scalogram_' + str(i))
        plt.ylabel('Scale')
        plt.xlabel('Time')
        plt.savefig(file_path)
        plt.tight_layout()
        plt.close()
    #Anomalies on a partial signal: scalograms to look at are the ones with numbers 4396, 4403, 4440, 4938-45, 4972-76, 10277, 10279, 12974-988
    # This is to extract features using Resnet50. Pick the output at the last but one layer of the network
    from pandas.core.arrays import numeric
'''    
import re
for col in cols:   
    df_for_feature_vectors = pd.DataFrame(columns = None)
    model = ResNet50(weights = 'imagenet', include_top = False, pooling = 'avg')
    file_path = '/home/user/Desktop/jupyter1/DDP/Scalograms_'+col+'_Sliding_50_5/'
    df_for_feature_vectors = pd.DataFrame()
    #error_indices = list()
    for infile in tqdm(glob.glob(file_path + '*.png')):
      fileindex = re.findall('[0-9]+', infile)
      fileindex = [int(i) for i in fileindex][1]
      img = image.load_img(infile)
      x = image.img_to_array(img)
      x = np.expand_dims(x, axis =0)
      x = preprocess_input(x)
    #   try:
      features = model.predict(x)[0]
      features_arr = np.char.mod('%f', features)
      df_for_feature_vectors = pd.concat((df_for_feature_vectors, pd.Series(features_arr).rename('FeatureVector_' +str(fileindex))),axis = 1)
      #df_for_feature_vectors['FeatureVector_' +str(fileindex)]= features_arr
    #   except:
    #     error_indices.append(fileindex)
    #     continue


    '''
      if k != n:
        if k % 1000 == 0: 
          print("files_completed " + str(k))
          df_for_feature_vectors.to_csv("Power_difference_features" + str(k) + ".csv")
      else:
        df_for_feature_vectors.to_csv("Power_difference_features_All.csv")
    '''
    df_for_feature_vectors.to_csv('/home/user/Desktop/jupyter1/DDP/Scalograms_'+col+'_Sliding_50_5/'+col+'_features_All.csv')

